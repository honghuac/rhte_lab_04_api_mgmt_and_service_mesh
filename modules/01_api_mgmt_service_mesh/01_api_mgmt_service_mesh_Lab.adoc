:noaudio:
:scrollbar:
:data-uri:
:toc2:
:linkattrs:

= API Mgmt and Service Mesh Lab

.Goals
* Inject Istio Envoy proxy configs into an Apicast gateway
* Configure an Istio Egress Route for an Apicast gateway
* End-to-end distributed tracing of a MSA application using Jaeger implementation of the _OpenTracing_ specification

.Prerequisite
* Skills
** Completion of the _APIs as a Business_ lab
** Completion of the _MSA and Service Mesh_ lab
* Tools
** `curl` utility
** `oc` version 3.9 utility

== Overview

== Setup

=== Environment Variables

-----
$ export REGION=<provided by your instructor>
$ export OCP_USER_ID=<provided by your instructor>
$ export API_ACCESS_TOKEN=<provided by your instructor>

$ export THREESCALE_PORTAL_ENDPOINT=https://${API_ACCESS_TOKEN}@$TENANT_NAME-admin.apps.$REGION.openshift.opentlc.com
$ export OCP_WILDCARD_DOMAIN=apps.$REGION.openshift.opentlc.com
$ export TENANT_NAME=$OCP_USER_ID-3scale
-----

=== OpenShift 

. Log into OpenShift
+
-----
$ oc login https://master.$REGION.openshift.opentlc.com -u $OCP_USER_ID -p <OCP user password provided by instructor>
-----

. Switch to your  OpenShift project
+
-----
$ oc project rhte-mw-api-mesh-$OCP_USER_ID
-----


=== CoolStore Catalog Service

=== About Deployment and DeploymentConfig 

The _Deployment_ construct is the more recent Kubernetes equivalent of what has always been in OpenShift:  _DeploymentConfig_.

The _istioctl_ utility (introduced later in this lab) of Istio requires the use of the Kubernetes _Deployment_ resource.
+
Subsequently, for the purpose of this lab, we'll use the Kubernetes _Deployment_ type (instead of DeploymentConfig) for all microservices.


The CoolStore catalog service included in your lab environment connects to a MongoDB database.
This MongoDB database is managed by Kubernetes using an OpenShift DeploymentConfig instead of a Kubernetes Deployment.
The reason for this is the the OpenShift DeploymentConfig provides more features than a Deployment to include the use of _lifecycle_ hooks.
This is important because the MongoDB in your lab is pre-seeded with data using a _post deployment_ life-cycle hook.
This _post deployment_ lifecycle hook is simply ignored when attempting to use a Kubernetes Deployment.


If you interested in learning more about the differences between Kubernetes _Deployments_ and OCP _DeploymentConfigurations_, please see
link:https://docs.openshift.com/container-platform/3.10/dev_guide/deployments/kubernetes_deployments.html#kubernetes-deployments-vs-deployment-configurations[this documentation].


=== Resources

. Review DeploymentConfig
+
-----
$ oc get dc

...

NAME              REVISION   DESIRED   CURRENT   TRIGGERED BY
catalog-mongodb   1          1         1         config,image(mongodb:3.4)
-----

. Review Deployment
+
-----
$ oc get deploy

...

NAME              DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
catalog-service   1         1         1            1           4m
-----

. Review running pods
+
-----
oc get pods

...

NAME                          READY     STATUS      RESTARTS   AGE
catalog-mongodb-1-clsz4       1/1       Running     0          11m
catalog-service-1-dqb28       1/1       Running     0          11m

...
-----

. Retrieve the URL of the Coolstore catalog microservice:
+
[source,text]
----
export CATALOG_URL=http://$(oc get route catalog-service -n $CATALOG_PRJ -o template --template='{{.spec.host}}')
----

. Via the catalog service, retrieve the pre-seeded data in the Mongo database:
+
-----
$ curl -X GET "$CATALOG_URL/products"
-----

== Invoke _Open API Specification_ docs

The link:https://swagger.io/docs/specification/about/[OpenAPI Specification^] (formerly "Swagger Specification") is an API description format for REST APIs. link:https://swagger.io/[Swagger^] is a set of open-source tools built around the OpenAPI specification that can help you design, build, document, and consume REST APIs.

Swagger documentation is available for the REST endpoints of the catalog microservice.

. Display the URL for your project:
+
[source,text]
----
echo $CATALOG_URL
----

. Copy and paste the URL into a web browser.
* Expect to see the Swagger docs for the REST endpoints:
+
image::images/swagger-ui-coolstore-catalog.png[]

. Click *GET /products Get a list of products* to expand the item.
. Click the *Try it out* button, then click *Execute*.
. View the REST call response:
+
image::images/swagger-ui-response.png[]

. Use the Swagger UI to test the other REST endpoints for the catalog microservice.

=== 3scale AMP

TO-DO :  Provide overview of pre-provisioned multi-tenant lab environment

== Apicast: Plain

=== Deploy Apicast

. Retrieve Apicast template
+
-----
$ curl -o /tmp/3scale-apicast-2.2.yml \
          https://raw.githubusercontent.com/gpe-mw-training/3scale_onpremise_implementation_labs/master/resources/rhte/3scale-apicast-2.2.yml
-----

. Review Apicast template
+
-----
$ cat /tmp/3scale-apicast-2.2.yml | more
-----

. Check your knowledge

. Create Apicast related resources in OpenShift:
+
-----
$ oc new-app \
     -f /tmp/3scale-apicast-2.2.yml \
     --param THREESCALE_PORTAL_ENDPOINT=$THREESCALE_PORTAL_ENDPOINT \
     --param TENANT_NAME=$TENANT_NAME \
     --param WILDCARD_DOMAIN=$OCP_WILDCARD_DOMAIN > /tmp/3scale_apicast_istio_details.txt
-----

. Resume the intially paused deploy object:
+
-----
$ oc rollout resume deploy apicast-prod-plain
-----

=== Configure and Test API Mgmt (Optional)

If you are new to API management using 3scale, it is recommended that you take this opportunity to refresh before continuing with the objectives of this lab.

You can do so by following the instructions found in the <<configuretestapi>> section of the appendix of this lab.

Upon completion, return back to this point in the lab and proceed with next section.

If you are already experienced using Red Hat 3scale, then feel free to just proceed to the next section.

== Apicast: Istio enabled

=== Overview

TO-DO:  Architecture diagram

=== Procedure

. View special privileges:
+
-----

TO-DO: view privileged scc on default sa

-----


. View configmap in `istio-system` project
+
-----
$ oc describe configmap istio -n istio-system | more
-----


. Inject Istio configs into a new apicast deployment
+
-----


# The password can be either the :
#   1) [provider key](https://support.3scale.net/docs/terminology#apikey) or 
#   2) [access token](https://support.3scale.net/docs/terminology#tokens) 
# Note: these should not be confused with [service tokens](https://support.3scale.net/docs/terminology#tokens)
# Example: `https://ACCESS-TOKEN@ACCOUNT-admin.3scale.net` (where the host name is the same as the domain for the URL when you are logged into the admin portal from a browser.
# When `THREESCALE_PORTAL_ENDPOINT` environment variable is provided, the gateway will download the configuration from the 3scale on initializing. 
# The configuration includes all the settings provided on the Integration page of the API(s).

# https://3e7d7556ff02f564ded302c6b1648e33@user1-3scale-admin.apps.dev39.openshift.opentlc.com

$ istioctl kube-inject \
           -f ~/lab/3scale_onpremise_implementation_labs/resources/apicast-deploy-istio.yml \
           >> ~/lab/3scale_onpremise_implementation_labs/resources/3scale-apicast-2.2-istio.yml

$ oc new-app \
     -f ~/lab/3scale_onpremise_implementation_labs/resources/3scale-apicast-2.2-istio.yml \
     --param THREESCALE_PORTAL_ENDPOINT=$THREESCALE_PORTAL_ENDPOINT \
     --param TENANT_NAME=$OCP_USER_ID-3scale \
     --param WILDCARD_DOMAIN=$OCP_WILDCARD_DOMAIN > /tmp/3scale_apicast_istio_details.txt
-----


. Resume pauased _apicast_
+
-----
-----


. Investigate _apicast_ provisioning problem
+
-----

...

2018/08/02 08:32:23 [warn] 23#23: *2 [lua] remote_v2.lua:163: call(): failed to get list of services: invalid status: 0 url: https://ratwater-admin.3scale.net/admin/api/services.json, context: ngx.timer
2018/08/02 08:32:23 [info] 23#23: *2 [lua] remote_v1.lua:98: call(): configuration request sent: https://ratwater-admin.3scale.net/admin/api/nginx/spec.json, context: ngx.timer
2018/08/02 08:32:23 [error] 23#23: *2 peer closed connection in SSL handshake, context: ngx.timer
2018/08/02 08:32:23 [warn] 23#23: *2 [lua] remote_v1.lua:108: call(): configuration download error: handshake failed, context: ngx.timer
ERROR: /opt/app-root/src/src/apicast/configuration_loader.lua:57: missing configuration
stack traceback:
	/opt/app-root/src/src/apicast/configuration_loader.lua:57: in function 'boot'
	/opt/app-root/src/libexec/boot.lua:6: in function 'file_gen'
	init_worker_by_lua:49: in function <init_worker_by_lua:47>
	[C]: in function 'xpcall'
	init_worker_by_lua:56: in function <init_worker_by_lua:54>

-----

. Configure a custom Istio _Egress Route_ for Apicast gateway
+
-----
-----

. Re-dploy Istio enabled Apicast gateway

. Modify _service_ to route to new Istio enabled _apicast_
+
-----
-----

. Test

== Jaeger UI

TO-DO : View OpenTracing spans in Jaeger UI

== Catalog Service: Istio enabled

== 3scale mixer adapter

TO-DO :  Juaquim will elaborate on this on Aug 9 during the 3scale F2F .


== Conclusion

As you know, Openresty is Nginx + luaJIT, and right now, we only get OpenTracing information for the "Nginx" part of it, there aren't any OpenTracing libraries for lua.
We are working on being able to use the OpenTracing C++ libraries from LUA, so we can create spans directly from it, and gain even more visibility into APIcast internals. 
For example, this could help debug if that custom policy you just installed is making things slower.

== Appendix


[[configuretestapi]]
=== Configure and Test API Mgmt

. Create Service
.. Click the `API` tab in the top toolbar.
.. Click `Create Service`
+
image::images/create_service.png[]


ifdef::showscript[]

export API_ACCESS_TOKEN=9a67667ef15213f421430aaa9fe3fa1ceab44f165324fdae30941d98110ea1ae

endif::showscript[]




